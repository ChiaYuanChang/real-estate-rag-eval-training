"""
## room title åˆ†ç¾¤ (V3 - é‡å°å®¢é¤å»³å„ªåŒ–)
- Data: ALL vlm_rematch_twhg room title
- Logic Rules:
  1. å„ªå…ˆæ’é™¤è¡›æµ´ã€‚
  2. æ’é™¤å…¬è¨­/å¤–éƒ¨/ç‰¹å®šéå±…ä½åŠŸèƒ½ (å¦‚: äº¤èª¼å»³, æ¢¯å»³, åº—é¢)ã€‚
  3. æ•æ‰ "å»³" é¡åˆ¥ (åŒ…å«: å®¢å»³, é¤å»³, å»šæˆ¿, å®¢é¤å»³, å§å°)ã€‚
  4. æ•æ‰ "æˆ¿" é¡åˆ¥ã€‚
  5. å‰©ä¸‹æ­¸é¡ç‚º "å…¶ä»–" (å¦‚: å–®ç¨çš„ç„é—œ, é™½å°, èµ°é“)ã€‚
"""

import json
import os
import re
from collections import Counter, defaultdict

# è¨­å®šæ‚¨çš„è³‡æ–™è·¯å¾‘
raw_data_folder_path: str = "../../../data/vlm_rematch_twhg_with_latlng_and_places/"


def clean_room_title(title: str) -> str:
    if not title:
        return ""
    # ç§»é™¤æ‹¬è™Ÿã€è‹±æ•¸å­—ã€ç‰¹æ®Šç¬¦è™Ÿ
    cleaned = re.sub(r'[\(ï¼ˆ].*?[\)ï¼‰]', '', title)
    cleaned = re.sub(r'[A-Za-z0-9]', '', cleaned)
    cleaned = re.sub(r'[/\+\-_]', '', cleaned)
    return cleaned.strip()


def classify_category(title: str) -> str:
    """
    åˆ†é¡é‚è¼¯æ ¸å¿ƒ
    """

    # --- 1. è¡› (æœ€æ˜ç¢ºï¼Œå„ªå…ˆæ’é™¤) ---
    bath_keywords = ['è¡›', 'æµ´', 'å»', 'æ´—æ‰‹']
    if any(k in title for k in bath_keywords):
        return 'è¡›(å»æ‰€/æµ´å®¤)'

    # --- 2. æ’é™¤éå±…ä½å€åŸŸ/å…¬è¨­ (å„ªå…ˆæ–¼ "å»³" çš„åˆ¤æ–·) ---
    # é€™è£¡è¦å°å¿ƒï¼Œä¸èƒ½èª¤æ®º "å®¢é¤å»³"
    # "æ¢¯å»³" å±¬æ–¼å…¬è¨­æˆ–éé“ï¼Œä¸å±¬æ–¼å®¤å…§å»³
    # "äº¤èª¼å»³" å±¬æ–¼å…¬è¨­
    public_or_external_keywords = [
        'äº¤èª¼', 'å¥èº«', 'éŠæˆ²', 'æ’çƒ', 'å…¬è¨­',
        'å¤§å»³', 'é–€å»³', 'æ¢¯å»³', 'æ«ƒå°', 'ä¿¡ç®±', 'ä¸­åº­',
        'åº—é¢', 'é¨æ¨“', 'å•†', 'è¾¦å…¬',
        'è»Š', 'åœ',
        'é ‚æ¨“', 'å¤–è§€', 'å¤§é–€', 'èŠ±åœ’', 'å…¥å£', 'å¤–ç‰†',
        'é›»ç®±', 'æ°´å¡”', 'æ©Ÿæˆ¿', 'åƒåœ¾'
    ]
    if any(k in title for k in public_or_external_keywords):
        return 'å…¶ä»–(å…¬è¨­/è»Šä½/å¤–éƒ¨/åº—é¢)'

    # --- 3. å»³ (å±…ä½ç”Ÿæ´»çš„å…¬å…±å€åŸŸ) ---
    # åŒ…å«: å®¢é¤å»³, å®¢å»³, é¤å»³, å»šæˆ¿
    # åªè¦å‘½ä¸­é€™è£¡ï¼Œå°±ç®—æ˜¯ "å®¢é¤å»³ç„é—œ" ä¹Ÿæœƒæ­¸é¡åœ¨æ­¤ (ç¬¦åˆä¸»è¦åŠŸèƒ½å„ªå…ˆåŸå‰‡)
    hall_keywords = [
        'å®¢å»³', 'å®¢é¤å»³', 'é¤å»³',  # å®Œæ•´è©å„ªå…ˆ
        'å»š', 'èµ·å±…',  # åŠŸèƒ½è©
        'é¤', 'å§', 'ä¸­å³¶',  # é¤å»³ç›¸é—œ
        # æ³¨æ„: ä¸å–®ç¨ä½¿ç”¨ 'å»³' å­—ï¼Œé¿å…èª¤åˆ¤å¥‡æ€ªçš„è¤‡åˆè©ï¼Œä½† 'å®¢' èˆ‡ 'é¤' å·²è¶³å¤ æ¶µè“‹
    ]
    # é¡å¤–è£œå¼·: å¦‚æœåŒ…å« "å»³" ä¸”ä¸åŒ…å« "æ¢¯" ç­‰è² é¢è© (é›–ç„¶ä¸Šé¢å·²æ’é™¤æ¢¯å»³ï¼Œä½†é›™é‡ä¿éšª)
    if any(k in title for k in hall_keywords) or ('å»³' in title and 'æ¢¯' not in title):
        return 'å»³(å®¢å»³/é¤å»³/å»šæˆ¿)'

    # --- 4. æˆ¿ (å±…ä½å€åŸŸ) ---
    room_keywords = ['è‡¥', 'æˆ¿', 'æ›¸æˆ¿', 'å’Œå®¤', 'å­è¦ª', 'æ›´è¡£å®¤']
    # æ›´è¡£å®¤æœ‰æ™‚ç®—å…¶ä»–ï¼Œä½†é€šå¸¸ä¾é™„æ–¼æˆ¿é–“ï¼Œè¦–éœ€æ±‚è€Œå®šï¼Œé€™è£¡æš«æ­¸æˆ¿æˆ–å¯ç§»è‡³å…¶ä»–
    if any(k in title for k in room_keywords):
        return 'æˆ¿(æ›¸æˆ¿/è‡¥å®¤/å®¢æˆ¿)'

    # --- 5. å®¤å…§å…¶ä»– (é™„å±¬ç©ºé–“) ---
    # å–®ç¨çš„ "ç„é—œ", "é™½å°", "èµ°é“" æœƒè½åˆ°é€™è£¡
    indoor_misc_keywords = [
        'ç„é—œ', 'é‹æ«ƒ',
        'èµ°å»Š', 'èµ°é“', 'æ¢¯', 'é€šé“',
        'é™½å°', 'éœ²å°', 'æ›¬è¡£',
        'å„²è—', 'å€‰', 'ç½®ç‰©'
    ]
    if any(k in title for k in indoor_misc_keywords):
        return 'å…¶ä»–(ç„é—œ/é™½å°/èµ°é“/å„²è—)'

    # --- 6. ç„¡æ³•è­˜åˆ¥ ---
    return 'æœªåˆ†é¡/å…¶ä»–'


def process_files(folder_path):
    json_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.json')]
    category_stats = defaultdict(Counter)

    # æ¸¬è©¦ç”¨ï¼šè¿½è¹¤ç‰¹å®šè©å½™çš„å»å‘
    test_cases = ['å®¢é¤å»³', 'å®¢é¤å»³ç„é—œ', 'ç„é—œ', 'äº¤èª¼å»³', 'æ¢¯å»³', 'é¤å§å€']
    test_logs = []

    print(f"é–‹å§‹è™•ç† {len(json_files)} å€‹ JSON æª”æ¡ˆ...")

    for file_path in json_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            result_list = data.get("matching_result_list", [])

            for item in result_list:
                extracted = item.get("extracted_feature", {})
                raw_room = extracted.get("room", "")

                if not raw_room:
                    continue

                clean_room = clean_room_title(raw_room)
                if not clean_room:
                    continue

                category = classify_category(clean_room)
                category_stats[category][clean_room] += 1

                # è¨˜éŒ„æˆ‘å€‘é—œå¿ƒçš„æ¸¬è©¦æ¡ˆä¾‹
                for case in test_cases:
                    if case in clean_room:
                        test_logs.append((clean_room, category))
                        break

        except Exception as e:
            print(f"Error processing file {file_path}: {e}")

    return category_stats, test_logs


# åŸ·è¡Œ
stats, logs = process_files(raw_data_folder_path)

# è¼¸å‡ºçµæœ
print("\n" + "=" * 50)
print("ã€å„åˆ†é¡çµ±è¨ˆçµæœã€‘")
print("=" * 50)

sort_order = [
    'å»³(å®¢å»³/é¤å»³/å»šæˆ¿)',
    'æˆ¿(æ›¸æˆ¿/è‡¥å®¤/å®¢æˆ¿)',
    'è¡›(å»æ‰€/æµ´å®¤)',
    'å…¶ä»–(ç„é—œ/é™½å°/èµ°é“/å„²è—)',
    'å…¶ä»–(å…¬è¨­/è»Šä½/å¤–éƒ¨/åº—é¢)',
    'æœªåˆ†é¡/å…¶ä»–'
]

for category in sort_order:
    if category in stats:
        word_counter = stats[category]
        print(f"\nğŸ“‚ åˆ†é¡: {category}")
        print(f"   ç¸½è¨ˆæ•¸é‡: {sum(word_counter.values())}")
        print(f"   è©é »åˆ†ä½ˆ (Top 5):")
        for word, count in word_counter.most_common():
            print(f"     - {word}: {count}")

print("\n" + "=" * 50)
print("ã€é‚è¼¯é©—è­‰ (é—œéµè©æª¢æŸ¥)ã€‘")
print("=" * 50)
# å»é‡å¾Œé¡¯ç¤ºæ¸¬è©¦æ¡ˆä¾‹çš„åˆ†é¡çµæœ
unique_logs = sorted(list(set(logs)), key=lambda x: x[1])
for room, cat in unique_logs:
    if any(k in room for k in ['å®¢é¤å»³', 'ç„é—œ', 'äº¤èª¼', 'æ¢¯å»³']):
        print(f"è©å½™: {room:<15} -> {cat}")
